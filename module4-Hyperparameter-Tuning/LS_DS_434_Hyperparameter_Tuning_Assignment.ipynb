{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9Ryp-TVm4njD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "metadata": {
        "id": "NNJ-tOBs4jM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "655ab0b6-904c-4835-f74b-2f438010f50a"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/cocoisland/DS-Unit-4-Sprint-3-Neural-Networks/master/module4-Hyperparameter-Tuning/WA_Fn-UseC_-Telco-Customer-Churn.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-04 20:54:05--  https://raw.githubusercontent.com/cocoisland/DS-Unit-4-Sprint-3-Neural-Networks/master/module4-Hyperparameter-Tuning/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 977501 (955K) [text/plain]\n",
            "Saving to: ‘WA_Fn-UseC_-Telco-Customer-Churn.csv’\n",
            "\n",
            "WA_Fn-UseC_-Telco-C 100%[===================>] 954.59K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-04-04 20:54:10 (21.5 MB/s) - ‘WA_Fn-UseC_-Telco-Customer-Churn.csv’ saved [977501/977501]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XPXZiPtWIkhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "590fd707-bb65-49aa-fde4-092d00e56f91"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  WA_Fn-UseC_-Telco-Customer-Churn.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFODEJGNIXln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "print(df.shape)\n",
        "df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xeARlx2tQDmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqlOsu7pYMtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e18044d9-93fc-4d97-cff2-4025b66c4875"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
              "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
              "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
              "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
              "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "9OYsp8A_J0Y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1d79dc0b-5653-442f-8dc1-713590a69e01"
      },
      "cell_type": "code",
      "source": [
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "y = df['Churn'].map({'Yes':1,'No':0})\n",
        "\n",
        "# customerID is unique random noise\n",
        "df1 = df.drop(['customerID','Churn'],axis=1)\n",
        "df1['TotalCharges']=df1['TotalCharges'].replace(' ',0).astype(float)\n",
        "\n",
        "encoder = ce.OrdinalEncoder(handle_unknown='ignore', \n",
        "                 cols=['gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                       'MultipleLines','InternetService','OnlineSecurity',\n",
        "                      'OnlineBackup','TechSupport','StreamingTV','StreamingMovies',\n",
        "                      'Contract','PaperlessBilling','PaymentMethod',\n",
        "                      'DeviceProtection'])\n",
        "X_enc = encoder.fit_transform(df1)\n",
        "scaler = StandardScaler()\n",
        "X_enc_std = scaler.fit_transform(X_enc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pQavq-1T6DK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X_enc.dtypes)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DG0XKHvia3Tz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e781bf8-f0dc-494d-abcd-572fbabf98c0"
      },
      "cell_type": "code",
      "source": [
        "X_enc_std.shape, y.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7043, 19), (7043,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "4u0qD7-XJkIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "595fdfc9-d804-4ec6-cc1c-2c850b2a01ac"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = X_enc_std\n",
        "Y = y\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=19, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "# best:batch 10, epoch=20\n",
        "# batch_size = [10, 20, 40, 60, 80, 100] \n",
        "# epoch = [20,40]\n",
        "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# learning rate (if applicable to optimizer)\n",
        "# momentum (if applicable to optimizer)\n",
        "# activation functions\n",
        "# network weight initialization\n",
        "# dropout regularization\n",
        "# number of neurons in the hidden layer\n",
        "\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid = {'batch_size': [10],\n",
        "              'epochs': [20],\n",
        "             'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']}\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8043447364617288 using {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adam'}\n",
            "Means: 0.8039187818160538, Stdev: 0.0031694817776395153 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'SGD'}\n",
            "Means: 0.8012210670290016, Stdev: 0.006121639617271853 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'RMSprop'}\n",
            "Means: 0.8006531282546387, Stdev: 0.004257068249722669 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adagrad'}\n",
            "Means: 0.80349282623099, Stdev: 0.0014368167655811402 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adadelta'}\n",
            "Means: 0.8043447364617288, Stdev: 0.0025899104512118196 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adam'}\n",
            "Means: 0.7989493085802168, Stdev: 0.004561942137594733 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adamax'}\n",
            "Means: 0.8009370980945887, Stdev: 0.002997477342900473 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D83pYydW4fhH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Kernel Initializer / Network weight Initialization"
      ]
    },
    {
      "metadata": {
        "id": "aHv2exH6rRaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "e51e5949-efb4-4c34-8cd1-f4b55a2e9aef"
      },
      "cell_type": "code",
      "source": [
        "def create_model(init_mode='uniform'):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=19, kernel_initializer=init_mode, activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "  # Compile model\n",
        " \n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam(lr=0.01), metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'batch_size': [10],\n",
        "              'epochs': [20],\n",
        "              'init_mode' : ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "              }\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8015050369620441 using {'batch_size': 10, 'epochs': 20, 'init_mode': 'glorot_normal'}\n",
            "Means: 0.796251594148609, Stdev: 0.0034340707284342417 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'uniform'}\n",
            "Means: 0.7949737301861953, Stdev: 0.006954058603008513 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'lecun_uniform'}\n",
            "Means: 0.7925599853406486, Stdev: 0.0027742655879583033 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'normal'}\n",
            "Means: 0.7346301292105356, Stdev: 0.0046012089443491205 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'zero'}\n",
            "Means: 0.8015050369620441, Stdev: 0.0016016848503678756 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'glorot_normal'}\n",
            "Means: 0.7990912939444973, Stdev: 0.0042196159009435085 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'glorot_uniform'}\n",
            "Means: 0.7986653386894891, Stdev: 0.004068461780134848 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'he_normal'}\n",
            "Means: 0.793695865919115, Stdev: 0.0038658844922868658 with: {'batch_size': 10, 'epochs': 20, 'init_mode': 'he_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oWeyR8n34q0Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learn rate and momentum for SGD only."
      ]
    },
    {
      "metadata": {
        "id": "n8_8ts-GqMVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "6b18a0d7-00c8-4909-c62c-eb19bcc059f4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import SGD, adam\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=19, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.804487 using {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.776374 (0.003394) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.784609 (0.005110) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "0.789720 (0.003539) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
            "0.795542 (0.001164) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
            "0.798807 (0.003370) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
            "0.795542 (0.007016) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
            "0.804487 (0.003560) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.800511 (0.004409) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "0.802357 (0.003225) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "0.801789 (0.003528) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
            "0.798807 (0.004882) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
            "0.798097 (0.003443) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
            "0.799801 (0.001602) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "0.799375 (0.004316) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
            "0.788158 (0.008392) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
            "0.792560 (0.007976) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
            "0.785177 (0.008464) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
            "0.778787 (0.025319) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
            "0.798807 (0.001755) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "0.794548 (0.004054) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
            "0.791140 (0.006333) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
            "0.783615 (0.011837) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
            "0.788016 (0.008039) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
            "0.734346 (0.005001) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
            "0.787023 (0.001533) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
            "0.788158 (0.013910) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
            "0.794832 (0.003310) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
            "0.788016 (0.009047) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
            "0.763169 (0.028968) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
            "0.734630 (0.004601) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UrWe0HTl94Lf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Best Parameter\n",
        "1. kernel initialization = glorot normal\n",
        "2. batch size = 10\n",
        "3. epoch = 20\n",
        "4. activation = linear\n",
        "5. learn rate = 0.01 , momentum=0 for SGD\n",
        "\n",
        "\n",
        "But accuracy all hovers around 0.84"
      ]
    },
    {
      "metadata": {
        "id": "yAXDul-x5ajf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "ae3a90ad-7c21-47d0-e4b3-6c27390ec797"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model(activation='relu'):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=19, kernel_initializer='glorot_normal', activation=activation))\n",
        "  model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\n",
        "  # Compile model\n",
        " \n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam(lr=0.01), metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'batch_size': [10],\n",
        "              'epochs': [20],\n",
        "              #'init_mode' : ['glorot_normal'],\n",
        "              'activation' : ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "              }\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8043447358439325 using {'activation': 'linear', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7932699110957179, Stdev: 0.002130368254130403 with: {'activation': 'softmax', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7958256397822119, Stdev: 0.0006843002359515638 with: {'activation': 'softplus', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7870225742444487, Stdev: 0.004911288676461447 with: {'activation': 'softsign', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7927019706541514, Stdev: 0.00466220651678623 with: {'activation': 'relu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7939798363599353, Stdev: 0.0036487194615499817 with: {'activation': 'tanh', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7969615191927895, Stdev: 0.00215604614704625 with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7932699110110882, Stdev: 0.008190555304269431 with: {'activation': 'hard_sigmoid', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.8043447358439325, Stdev: 0.0043974256928411976 with: {'activation': 'linear', 'batch_size': 10, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FfZRtJ7MCN3x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}