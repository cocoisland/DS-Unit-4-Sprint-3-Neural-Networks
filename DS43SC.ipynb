{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS43SC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocoisland/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/DS43SC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y6SKlgYrpcym",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks Sprint Challenge"
      ]
    },
    {
      "metadata": {
        "id": "BrEbRrjVphPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1) Define the following terms:\n",
        "\n",
        "1. Neuron - The neuron is nothing more than a set of inputs, a set of weights, and an activation function. The neuron translates these inputs into a single output, which can then be picked up as input for another layer of neurons later on.\n",
        "\n",
        "2. Input Layer - The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.\n",
        "\n",
        "3. Hidden Layer The hidden layers' job is to transform the inputs into something that the output layer can use.\n",
        "\n",
        "4. Output Layer - The output layer transforms the hidden layer activations into whatever scale you wanted your output to be on.\n",
        "\n",
        "5. Activation - squashes the values in a smaller range viz. a Sigmoid activation function squashes values between a range 0 to 1. There are many activation functions used in deep learning industry and ReLU, SeLU and TanH are preferred over sigmoid activation function.\n",
        "\n",
        "6. Backpropagation - information going back from the error cost backward through the network in order to compute the gradient or re-adjust the weights. It is refitting the neural network to minimize the error cost function."
      ]
    },
    {
      "metadata": {
        "id": "Q5EksLqnp4oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " YOUR ANSWER HERE"
      ]
    },
    {
      "metadata": {
        "id": "Ri_gRA2Jp728",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 1  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 1  | 0 |"
      ]
    },
    {
      "metadata": {
        "id": "ZMGCDbOfI0LC",
        "colab_type": "code",
        "outputId": "96e5488d-9ddb-4797-b306-006613b4e1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([(1,1,1), (1,0,1), (0,1,1), (1,0,1)], dtype=float)\n",
        "y = np.array([1,0,0,0], dtype=float)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 3), (4,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Ig6ZTH8tpQ19",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron(object):\n",
        "  def __init__(self, rate = 0.01, niter = 10):\n",
        "    self.rate = rate\n",
        "    self.niter = niter\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"Fit training data\n",
        "    X : Training vectors, X.shape : [#samples, #features]\n",
        "    y : Target values, y.shape : [#samples]\n",
        "    \"\"\"\n",
        "\n",
        "    # weights\n",
        "    self.weight = np.zeros(1 + X.shape[1]).astype(float)\n",
        "\n",
        "    # Number of misclassifications\n",
        "    self.errors = []  # Number of misclassifications\n",
        "\n",
        "    for i in range(self.niter):\n",
        "      err = 0\n",
        "      for xi, target in zip(X, y):\n",
        "        delta_w = self.rate * (target - self.predict(xi))\n",
        "        self.weight[1:] += delta_w * xi\n",
        "        self.weight[0] += delta_w\n",
        "        err += int(delta_w != 0.0)\n",
        "      self.errors.append(err)\n",
        "    return self\n",
        "\n",
        "  def net_input(self, X):\n",
        "    \"\"\"Calculate net input\"\"\"\n",
        "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "    \n",
        "  def predict(self, X):\n",
        "    \"\"\"Return class label after unit step\"\"\"\n",
        "   \n",
        "    return np.where(self.net_input(X) >= 0.5, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BcZNnNMIGvg",
        "colab_type": "code",
        "outputId": "701dc7a0-8057-4cdf-89d1-ca019b732f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pn = Perceptron(1, 10000)\n",
        "pn.fit(X, y)\n",
        "pn.predict(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "86HyRi8Osr3U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
        "- Your network must have one hidden layer. \n",
        "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
        "- Train your model on the Heart Disease dataset from UCI:\n",
        "\n",
        "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
        "\n",
        "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
      ]
    },
    {
      "metadata": {
        "id": "CNfiajv3v4Ed",
        "colab_type": "code",
        "outputId": "d097d154-bc5f-46b0-9b9a-e42bbe00251d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-05 15:43:21--  https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11328 (11K) [text/plain]\n",
            "Saving to: ‘heart.csv’\n",
            "\n",
            "\rheart.csv             0%[                    ]       0  --.-KB/s               \rheart.csv           100%[===================>]  11.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-05 15:43:21 (130 MB/s) - ‘heart.csv’ saved [11328/11328]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TP4pjOXVKz-l",
        "colab_type": "code",
        "outputId": "2e6873b3-4e67-42c8-f248-f00f43614679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('heart.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "2hv8zl-rbhk0",
        "colab_type": "code",
        "outputId": "491ad806-2ef2-43cb-e298-ebe800fceae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "0ajTbym8LBBh",
        "colab_type": "code",
        "outputId": "0808b601-b30f-40c8-9352-e03442de01c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X=df.drop('target',axis=1).values.astype(float)\n",
        "y=df.target.values.reshape(-1,1)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((303, 13), (303, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "yQ5x0gcSLaNu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    self.inputs = 13\n",
        "    self.hiddenNodes = 16\n",
        "    self.outputNodes = 1\n",
        "\n",
        "    # Initlize Weights\n",
        "    self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) # (13x6)\n",
        "    self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes) # (6x1)\n",
        "    \n",
        "\n",
        "  def feed_forward(self, X):\n",
        "    # Weighted sum between inputs and hidden layer\n",
        "    self.hidden_sum = np.dot(X, self.L1_weights)\n",
        "    # Activations of weighted sum\n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    # Weighted sum between hidden and output\n",
        "    self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
        "    # final activation of output\n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    return self.activated_output\n",
        "    \n",
        "  def sigmoid(self, s):\n",
        "    return 1/(1+np.exp(-s))\n",
        "  \n",
        "  # RuntimeWarning: overflow encountered in exp\n",
        "  #def sigmoid(self,s):\n",
        "  #  if -s > np.log(np.finfo(type(s)).max):\n",
        "  #      return 0.0    \n",
        "  #  a = np.exp(-s)\n",
        "  #  return 1.0/ (1.0 + a)\n",
        "  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1 - s)\n",
        "  \n",
        "  def backward(self, X, y, o):\n",
        "    # backward propgate through the network\n",
        "    self.o_error = y - o # error in output\n",
        "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
        "    \n",
        "    self.z2_error = self.o_delta.dot(self.L2_weights.T) # z2 error: how much our hidden layer weights contributed to output error\n",
        "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) # applying derivative of sigmoid to z2 error\n",
        "\n",
        "    self.L1_weights += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
        "    self.L2_weights += self.activated_hidden.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
        "    \n",
        "  def train (self, X, y):\n",
        "    o = self.feed_forward(X)\n",
        "    self.backward(X, y, o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQeMRO1fMLBI",
        "colab_type": "code",
        "outputId": "6b6709e2-2c3d-4115-9dec-7978b15bdc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "cell_type": "code",
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(100): # trains the NN 1,000 times\n",
        "  if i+1 in [1,2,3,4,5] or (i+1) % 50 == 0:\n",
        "    print('+---------- EPOCH', i+1, '-----------+')\n",
        "    #print(\"Input: \\n\", X) \n",
        "    #print(\"Actual Output: \\n\", y)  \n",
        "    #print(\"Predicted Output: \\n\" + str(NN.feed_forward(X))) \n",
        "    print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feed_forward(X))))) # mean sum squared loss\n",
        "    print(\"\\n\")\n",
        "  NN.train(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------- EPOCH 1 -----------+\n",
            "Loss: \n",
            "0.44707792229767274\n",
            "\n",
            "\n",
            "+---------- EPOCH 2 -----------+\n",
            "Loss: \n",
            "0.5443442221291408\n",
            "\n",
            "\n",
            "+---------- EPOCH 3 -----------+\n",
            "Loss: \n",
            "0.5442560996521041\n",
            "\n",
            "\n",
            "+---------- EPOCH 4 -----------+\n",
            "Loss: \n",
            "0.5440642144937643\n",
            "\n",
            "\n",
            "+---------- EPOCH 5 -----------+\n",
            "Loss: \n",
            "0.5434467034172835\n",
            "\n",
            "\n",
            "+---------- EPOCH 50 -----------+\n",
            "Loss: \n",
            "0.5445544554454586\n",
            "\n",
            "\n",
            "+---------- EPOCH 100 -----------+\n",
            "Loss: \n",
            "0.5445544554454586\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGT1oRzXw3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
        "\n",
        "- Use the Heart Disease Dataset (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network. \n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
        "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
      ]
    },
    {
      "metadata": {
        "id": "46UUGa1Fg4bQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHkq2BePf0oM",
        "colab_type": "code",
        "outputId": "1094124e-a1f0-4798-f286-48a9c2fa8153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "def create_model(activation='relu'):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=13, kernel_initializer='glorot_normal', activation=activation))\n",
        "  model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\n",
        "  # Compile model\n",
        " \n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Create pipeline\n",
        "#pipeline = make_pipeline(\\\n",
        "#                         ce.BinaryEncoder(),\n",
        "#                         RobustScaler(), \n",
        "#                         KerasClassifier(build_fn=create_model, verbose=1))\n",
        "# Model validation.\n",
        "#param_grid = {\n",
        "#    'kerasclassifier__batch_size': [20, 50, 80, 100, 200],\n",
        "#    'kerasclassifier__activation': ['tanh']\n",
        "#}\n",
        "\n",
        "#gridsearch = GridSearchCV(pipeline, param_grid=param_grid, cv=3, \n",
        "#                         scoring='accuracy', verbose=10\n",
        "\n",
        "\n",
        "param_grid = {'batch_size': [10,20],\n",
        "              'epochs': [20],\n",
        "              #'init_mode' : ['glorot_normal'],\n",
        "              'activation' : ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "              }\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8910891065503111 using {'activation': 'relu', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.15181518102636432, Stdev: 0.214699087981611 with: {'activation': 'softmax', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.24092409324527966, Stdev: 0.33374154115013854 with: {'activation': 'softmax', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.21122112230892623, Stdev: 0.2987117758289498 with: {'activation': 'softplus', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.702970297619848, Stdev: 0.21976332381525265 with: {'activation': 'softplus', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.25082508718023205, Stdev: 0.30595323848214345 with: {'activation': 'softsign', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.24752475316375003, Stdev: 0.2893393896468499 with: {'activation': 'softsign', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.21122112230892623, Stdev: 0.2987117758289498 with: {'activation': 'relu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.8910891065503111, Stdev: 0.1540232626067211 with: {'activation': 'relu', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.2673267348863111, Stdev: 0.2513889797575734 with: {'activation': 'tanh', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.23102310324462727, Stdev: 0.30595323361752097 with: {'activation': 'tanh', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.22112211152271863, Stdev: 0.3127138890560047 with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.21122112230892623, Stdev: 0.2987117758289498 with: {'activation': 'sigmoid', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.20792079247263792, Stdev: 0.29404440461416625 with: {'activation': 'hard_sigmoid', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.19471947037347476, Stdev: 0.27537491586027407 with: {'activation': 'hard_sigmoid', 'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.6435643607633735, Stdev: 0.2646856437368788 with: {'activation': 'linear', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.4554455453413154, Stdev: 0.41308215348345934 with: {'activation': 'linear', 'batch_size': 20, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}